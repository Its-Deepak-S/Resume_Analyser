{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6078a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec267dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from spacy import displacy\n",
    "import pyLDAvis.gensim_models\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Data loading/ Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "\n",
    "#nltk\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(['stopwords','wordnet'])\n",
    "\n",
    "#warning\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Resume.csv\")\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "data = df.copy().iloc[\n",
    "    0:200,\n",
    "]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36add779",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "skill_pattern_path = \"jz_skill_patterns.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ed692",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.from_disk(skill_pattern_path)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f78a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skills(text):\n",
    "    doc = nlp(text)\n",
    "    myset = []\n",
    "    subset = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"SKILL\":\n",
    "            subset.append(ent.text)\n",
    "    myset.append(subset)\n",
    "    return subset\n",
    "\n",
    "\n",
    "def unique_skills(x):\n",
    "    return list(set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acfdb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = []\n",
    "for i in range(data.shape[0]):\n",
    "    review = re.sub(\n",
    "        '(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\"',\n",
    "        \" \",\n",
    "        data[\"Resume_str\"].iloc[i],\n",
    "    )\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    lm = WordNetLemmatizer()\n",
    "    review = [\n",
    "        lm.lemmatize(word)\n",
    "        for word in review\n",
    "        if not word in set(stopwords.words(\"english\"))\n",
    "    ]\n",
    "    review = \" \".join(review)\n",
    "    clean.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Clean_Resume\"] = clean\n",
    "data[\"skills\"] = data[\"Clean_Resume\"].str.lower().apply(get_skills)\n",
    "data[\"skills\"] = data[\"skills\"].apply(unique_skills)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c24067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_resume=\"\"\"DEEPAK S deepaksridar2@gmail.com ⋄ www.linkedin.com/in/deepak035 ⋄ https://github.com/Its-Deepak-S\n",
    " OBJECTIVE\n",
    " I am a budding ML Engineer who’s passionate about Deep Learning and Data Science. I am always looking for\n",
    " opportunities to utilize my skills and knowledge on real- world tasks and upskilling myself in the process.\n",
    " EDUCATION\n",
    " B.Tech CSE (Specialization in AIML), Jain(Deemed-to-be University)\n",
    " Class 12, Chavara Public School\n",
    " SKILLS\n",
    " Expected 2025\n",
    " 2020-2021\n",
    " Technical Skills\n",
    " Soft Skills\n",
    " Languages\n",
    " EXPERIENCE\n",
    " Deep Learning, Python, Computer Vision, MySQL, Java, JavaScript\n",
    " Communication, Problem Solving, Teamwork, Interpersonal Skills\n",
    " English, Malayalam, Hindi\n",
    " Intern in Artificial Intelligence\n",
    " Corizo\n",
    " Intern in Full-stack Development\n",
    " Capabl\n",
    " PROJECTS\n",
    " 05/23- 06/23\n",
    " 06/23- 07/23\n",
    " Image Generation GAN: Image Generation GAN leverages Generative Adversarial Networks (GANs) on Fashion\n",
    " MNIST data to produce realistic fashion images, showcasing the power of deep learning in generating synthetic data\n",
    " with high fidelity and diversity.\n",
    " Resume Analyzer: A project that utilizes Natural Language Processing techniques to parse and analyze resumes,\n",
    " extracting key information such as skills, experience, and qualifications, streamlining the recruitment process with\n",
    " efficiency and accuracy\n",
    " Real-time Face and Eye Detection: A powerful computer vision project that utilizes advanced algorithms to\n",
    " detect and track faces and eyes in real-time video streams\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613367a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"Job-Category\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\",\n",
    "    \"SKILL\": \"linear-gradient(90deg, #9BE15D, #00E3AE)\",\n",
    "    \"ORG\": \"#ffd966\",\n",
    "    \"PERSON\": \"#e06666\",\n",
    "    \"GPE\": \"#9fc5e8\",\n",
    "    \"DATE\": \"#c27ba0\",\n",
    "    \"ORDINAL\": \"#674ea7\",\n",
    "    \"PRODUCT\": \"#f9cb9c\",\n",
    "}\n",
    "options = {\n",
    "    \"ents\": [\n",
    "        \"Job-Category\",\n",
    "        \"SKILL\",\n",
    "        \"ORG\",\n",
    "        \"PERSON\",\n",
    "        \"GPE\",\n",
    "        \"DATE\",\n",
    "        \"ORDINAL\",\n",
    "        \"PRODUCT\",\n",
    "    ],\n",
    "    \"colors\": colors,\n",
    "}\n",
    "sent = nlp(data[\"Resume_str\"].iloc[5])\n",
    "displacy.render(sent, style=\"ent\", jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdedbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = nlp(input_resume)\n",
    "displacy.render(sent2, style=\"ent\", jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_skills=\"\"\"Deep Learning, Data Science, AI, Computer Vision\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f5ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_skills = inp_skills.lower().split(\",\")\n",
    "resume_skills = unique_skills(get_skills(input_resume.lower()))\n",
    "score = 0\n",
    "for x in req_skills:\n",
    "    if x in resume_skills:\n",
    "        score += 1\n",
    "req_skills_len = len(req_skills)\n",
    "match = round(score / req_skills_len * 100, 1)\n",
    "\n",
    "print(f\"The current Resume is {match}% matched to your requirements\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
